{
  final Path outputPath=FileOutputFormat.getOutputPath(context);
  final Path outputdir=new FileOutputCommitter(outputPath,context).getWorkPath();
  final Configuration conf=context.getConfiguration();
  final FileSystem fs=outputdir.getFileSystem(conf);
  final long maxsize=conf.getLong(HConstants.HREGION_MAX_FILESIZE,HConstants.DEFAULT_MAX_FILE_SIZE);
  final String defaultCompressionStr=conf.get("hfile.compression",Compression.Algorithm.NONE.getName());
  final Algorithm defaultCompression=HFileWriterImpl.compressionByName(defaultCompressionStr);
  final boolean compactionExclude=conf.getBoolean("hbase.mapreduce.hfileoutputformat.compaction.exclude",false);
  final Map<byte[],Algorithm> compressionMap=createFamilyCompressionMap(conf);
  final Map<byte[],BloomType> bloomTypeMap=createFamilyBloomTypeMap(conf);
  final Map<byte[],Integer> blockSizeMap=createFamilyBlockSizeMap(conf);
  String dataBlockEncodingStr=conf.get(DATABLOCK_ENCODING_OVERRIDE_CONF_KEY);
  final Map<byte[],DataBlockEncoding> datablockEncodingMap=createFamilyDataBlockEncodingMap(conf);
  final DataBlockEncoding overriddenEncoding;
  if (dataBlockEncodingStr != null) {
    overriddenEncoding=DataBlockEncoding.valueOf(dataBlockEncodingStr);
  }
 else {
    overriddenEncoding=null;
  }
  return new RecordWriter<ImmutableBytesWritable,V>(){
    private final Map<byte[],WriterLength> writers=new TreeMap<byte[],WriterLength>(Bytes.BYTES_COMPARATOR);
    private byte[] previousRow=HConstants.EMPTY_BYTE_ARRAY;
    private final byte[] now=Bytes.toBytes(System.currentTimeMillis());
    private boolean rollRequested=false;
    @Override public void write(    ImmutableBytesWritable row,    V cell) throws IOException {
      KeyValue kv=KeyValueUtil.ensureKeyValue(cell);
      if (row == null && kv == null) {
        rollWriters();
        return;
      }
      byte[] rowKey=CellUtil.cloneRow(kv);
      long length=kv.getLength();
      byte[] family=CellUtil.cloneFamily(kv);
      WriterLength wl=this.writers.get(family);
      if (wl == null) {
        fs.mkdirs(new Path(outputdir,Bytes.toString(family)));
      }
      if (wl != null && wl.written + length >= maxsize) {
        this.rollRequested=true;
      }
      if (rollRequested && Bytes.compareTo(this.previousRow,rowKey) != 0) {
        rollWriters();
      }
      if (wl == null || wl.writer == null) {
        wl=getNewWriter(family,conf);
      }
      kv.updateLatestStamp(this.now);
      wl.writer.append(kv);
      wl.written+=length;
      this.previousRow=rowKey;
    }
    private void rollWriters() throws IOException {
      for (      WriterLength wl : this.writers.values()) {
        if (wl.writer != null) {
          LOG.info("Writer=" + wl.writer.getPath() + ((wl.written == 0) ? "" : ", wrote=" + wl.written));
          close(wl.writer);
        }
        wl.writer=null;
        wl.written=0;
      }
      this.rollRequested=false;
    }
    @edu.umd.cs.findbugs.annotations.SuppressWarnings(value="BX_UNBOXING_IMMEDIATELY_REBOXED",justification="Not important") private WriterLength getNewWriter(    byte[] family,    Configuration conf) throws IOException {
      WriterLength wl=new WriterLength();
      Path familydir=new Path(outputdir,Bytes.toString(family));
      Algorithm compression=compressionMap.get(family);
      compression=compression == null ? defaultCompression : compression;
      BloomType bloomType=bloomTypeMap.get(family);
      bloomType=bloomType == null ? BloomType.NONE : bloomType;
      Integer blockSize=blockSizeMap.get(family);
      blockSize=blockSize == null ? HConstants.DEFAULT_BLOCKSIZE : blockSize;
      DataBlockEncoding encoding=overriddenEncoding;
      encoding=encoding == null ? datablockEncodingMap.get(family) : encoding;
      encoding=encoding == null ? DataBlockEncoding.NONE : encoding;
      Configuration tempConf=new Configuration(conf);
      tempConf.setFloat(HConstants.HFILE_BLOCK_CACHE_SIZE_KEY,0.0f);
      HFileContextBuilder contextBuilder=new HFileContextBuilder().withCompression(compression).withChecksumType(HStore.getChecksumType(conf)).withBytesPerCheckSum(HStore.getBytesPerChecksum(conf)).withBlockSize(blockSize);
      contextBuilder.withDataBlockEncoding(encoding);
      HFileContext hFileContext=contextBuilder.build();
      wl.writer=new StoreFile.WriterBuilder(conf,new CacheConfig(tempConf),fs).withOutputDir(familydir).withBloomType(bloomType).withComparator(CellComparator.COMPARATOR).withFileContext(hFileContext).build();
      this.writers.put(family,wl);
      return wl;
    }
    private void close(    final StoreFile.Writer w) throws IOException {
      if (w != null) {
        w.appendFileInfo(StoreFile.BULKLOAD_TIME_KEY,Bytes.toBytes(System.currentTimeMillis()));
        w.appendFileInfo(StoreFile.BULKLOAD_TASK_KEY,Bytes.toBytes(context.getTaskAttemptID().toString()));
        w.appendFileInfo(StoreFile.MAJOR_COMPACTION_KEY,Bytes.toBytes(true));
        w.appendFileInfo(StoreFile.EXCLUDE_FROM_MINOR_COMPACTION_KEY,Bytes.toBytes(compactionExclude));
        w.appendTrackedTimestampsToMetadata();
        w.close();
      }
    }
    @Override public void close(    TaskAttemptContext c) throws IOException, InterruptedException {
      for (      WriterLength wl : this.writers.values()) {
        close(wl.writer);
      }
    }
  }
;
}
