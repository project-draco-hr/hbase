{
  try {
    Class dfsUtilClazz=Class.forName("org.apache.hadoop.hdfs.DFSUtil");
    dfsUtilClazz.getMethod("getNNServiceRpcAddresses",Configuration.class);
  }
 catch (  Exception e) {
    LOG.info("Skip testIsSameHdfs test case because of the no-HA hadoop version.");
    return;
  }
  Configuration conf=HBaseConfiguration.create();
  Path srcPath=new Path("hdfs://localhost:8020/");
  Path desPath=new Path("hdfs://127.0.0.1/");
  FileSystem srcFs=srcPath.getFileSystem(conf);
  FileSystem desFs=desPath.getFileSystem(conf);
  assertTrue(FSHDFSUtils.isSameHdfs(conf,srcFs,desFs));
  desPath=new Path("hdfs://127.0.0.1:8070/");
  desFs=desPath.getFileSystem(conf);
  assertTrue(!FSHDFSUtils.isSameHdfs(conf,srcFs,desFs));
  desPath=new Path("hdfs://127.0.1.1:8020/");
  desFs=desPath.getFileSystem(conf);
  assertTrue(!FSHDFSUtils.isSameHdfs(conf,srcFs,desFs));
  conf.set("fs.defaultFS","hdfs://haosong-hadoop");
  conf.set("dfs.nameservices","haosong-hadoop");
  conf.set("dfs.ha.namenodes.haosong-hadoop","nn1,nn2");
  conf.set("dfs.client.failover.proxy.provider.haosong-hadoop","org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider");
  conf.set("dfs.namenode.rpc-address.haosong-hadoop.nn1","127.0.0.1:8020");
  conf.set("dfs.namenode.rpc-address.haosong-hadoop.nn2","127.10.2.1:8000");
  desPath=new Path("/");
  desFs=desPath.getFileSystem(conf);
  assertTrue(FSHDFSUtils.isSameHdfs(conf,srcFs,desFs));
  conf.set("dfs.namenode.rpc-address.haosong-hadoop.nn1","127.10.2.1:8020");
  conf.set("dfs.namenode.rpc-address.haosong-hadoop.nn2","127.0.0.1:8000");
  desPath=new Path("/");
  desFs=desPath.getFileSystem(conf);
  assertTrue(!FSHDFSUtils.isSameHdfs(conf,srcFs,desFs));
}
