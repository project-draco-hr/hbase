{
  Logger.getLogger("org.apache.hadoop.mapred").setLevel(Level.DEBUG);
  conf.setInt("hbase.hregion.memcache.flush.size",1024 * 1024);
  conf.setLong("hbase.hregion.max.filesize",1024 * 1024);
  conf.setInt("hbase.hstore.compactionThreshold",2);
  desc=new HTableDescriptor(TABLE_NAME);
  desc.addFamily(new HColumnDescriptor(INPUT_COLUMN));
  desc.addFamily(new HColumnDescriptor(OUTPUT_COLUMN));
  dfsCluster=new MiniDFSCluster(conf,1,true,(String[])null);
  this.conf.set(HConstants.HBASE_DIR,this.dfsCluster.getFileSystem().getHomeDirectory().toString());
  super.setUp();
  try {
    dir=new Path("/hbase");
    fs.mkdirs(dir);
    hCluster=new MiniHBaseCluster(conf,1,dfsCluster,true);
    HBaseAdmin admin=new HBaseAdmin(conf);
    admin.createTable(desc);
    makeMultiRegionTable(conf,hCluster,this.fs,TABLE_NAME,INPUT_COLUMN);
    HTable table=new HTable(conf,new Text(TABLE_NAME));
    Text[] startKeys=table.getStartKeys();
    assertTrue(startKeys.length > 1);
  }
 catch (  Exception e) {
    StaticTestEnvironment.shutdownDfs(dfsCluster);
    throw e;
  }
  LOG.debug("\n\n\n\n\t\t\tSetup Complete\n\n\n\n");
}
