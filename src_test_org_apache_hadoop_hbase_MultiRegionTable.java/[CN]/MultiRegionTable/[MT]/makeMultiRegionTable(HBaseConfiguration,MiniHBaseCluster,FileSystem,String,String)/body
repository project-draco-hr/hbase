{
  final int retries=10;
  final long waitTime=20L * 1000L;
  assertTrue(conf.getLong("hbase.hregion.max.filesize",HConstants.DEFAULT_MAX_FILE_SIZE) <= 1024 * 1024);
  assertNotNull(fs);
  Path d=fs.makeQualified(new Path(conf.get(HConstants.HBASE_DIR)));
  HTable meta=new HTable(conf,HConstants.META_TABLE_NAME);
  int count=count(meta,tableName);
  HTable t=new HTable(conf,new Text(tableName));
  HRegionInfo parent=t.getRegionLocation(HConstants.EMPTY_START_ROW).getRegionInfo();
  LOG.info("Parent region " + parent.toString());
  Path parentDir=HRegion.getRegionDir(new Path(d,tableName),parent.getEncodedName());
  assertTrue(fs.exists(parentDir));
  addContent(new HTableIncommon(t),columnName);
  LOG.info("Finished content loading");
  HRegionInfo hri=null;
  HRegion r=null;
  for (int i=0; i < 30; i++) {
    hri=t.getRegionLocation(HConstants.EMPTY_START_ROW).getRegionInfo();
    LOG.info("Region location: " + hri);
    r=cluster.getRegionThreads().get(0).getRegionServer().onlineRegions.get(hri.getRegionName());
    if (r != null) {
      break;
    }
    try {
      Thread.sleep(1000);
    }
 catch (    InterruptedException e) {
      LOG.warn("Waiting on region to come online",e);
    }
  }
  cluster.getRegionThreads().get(0).getRegionServer().getCacheFlushListener().flushRequested(r);
  int oldCount=count;
  for (int i=0; i < retries; i++) {
    count=count(meta,tableName);
    if (count > oldCount) {
      break;
    }
    try {
      Thread.sleep(waitTime);
    }
 catch (    InterruptedException e) {
    }
  }
  if (count <= oldCount) {
    throw new IOException("Failed waiting on splits to show up");
  }
  Map<Text,byte[]> data=getSplitParentInfo(meta,parent);
  if (data == null) {
  }
 else {
    parent=Writables.getHRegionInfoOrNull(data.get(HConstants.COL_REGIONINFO));
    LOG.info("Found parent region: " + parent);
    assertTrue(parent.isOffline());
    assertTrue(parent.isSplit());
    HRegionInfo splitA=Writables.getHRegionInfoOrNull(data.get(HConstants.COL_SPLITA));
    HRegionInfo splitB=Writables.getHRegionInfoOrNull(data.get(HConstants.COL_SPLITB));
    assertTrue(fs.exists(parentDir));
    LOG.info("Split happened. Parent is " + parent.getRegionName());
    recalibrate(t,new Text(columnName),retries,waitTime);
    if (splitA == null) {
      LOG.info("splitA was already null. Assuming it was previously compacted.");
    }
 else {
      LOG.info("Daughter splitA: " + splitA.getRegionName());
      compact(cluster,splitA);
      while (true) {
        data=getSplitParentInfo(meta,parent);
        if (data == null || data.size() == 3) {
          try {
            Thread.sleep(waitTime);
          }
 catch (          InterruptedException e) {
          }
          continue;
        }
        break;
      }
      LOG.info("Parent split info returned " + data.keySet().toString());
    }
    if (splitB == null) {
      LOG.info("splitB was already null. Assuming it was previously compacted.");
    }
 else {
      LOG.info("Daughter splitB: " + splitA.getRegionName());
      compact(cluster,splitB);
    }
    LOG.info("Waiting on parent " + parent.getRegionName() + " to disappear");
    for (int i=0; i < retries; i++) {
      if (getSplitParentInfo(meta,parent) == null) {
        break;
      }
      try {
        Thread.sleep(waitTime);
      }
 catch (      InterruptedException e) {
      }
    }
    assertNull(getSplitParentInfo(meta,parent));
  }
  for (int i=0; i < retries; i++) {
    if (!fs.exists(parentDir)) {
      break;
    }
    try {
      Thread.sleep(waitTime);
    }
 catch (    InterruptedException e) {
    }
  }
  assertFalse(fs.exists(parentDir));
}
