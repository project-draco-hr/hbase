{
  Preconditions.checkState(status == null);
  Preconditions.checkArgument(logfile.isFile(),"passed in file status is for something other than a regular file.");
  boolean isCorrupted=false;
  boolean skipErrors=conf.getBoolean("hbase.hlog.split.skip.errors",SPLIT_SKIP_ERRORS_DEFAULT);
  int interval=conf.getInt("hbase.splitlog.report.interval.loglines",1024);
  Path logPath=logfile.getPath();
  boolean outputSinkStarted=false;
  boolean progress_failed=false;
  int editsCount=0;
  int editsSkipped=0;
  status=TaskMonitor.get().createStatus("Splitting log file " + logfile.getPath() + "into a temporary staging area.");
  Reader in=null;
  this.fileBeingSplit=logfile;
  try {
    long logLength=logfile.getLen();
    LOG.info("Splitting wal: " + logPath + ", length="+ logLength);
    LOG.info("DistributedLogReplay = " + this.distributedLogReplay);
    status.setStatus("Opening log file");
    if (reporter != null && !reporter.progress()) {
      progress_failed=true;
      return false;
    }
    try {
      in=getReader(logfile,skipErrors,reporter);
    }
 catch (    CorruptedLogFileException e) {
      LOG.warn("Could not get reader, corrupted log file " + logPath,e);
      ZKSplitLog.markCorrupted(rootDir,logfile.getPath().getName(),fs);
      isCorrupted=true;
    }
    if (in == null) {
      LOG.warn("Nothing to split in log file " + logPath);
      return true;
    }
    int numOpenedFilesBeforeReporting=conf.getInt("hbase.splitlog.report.openedfiles",3);
    int numOpenedFilesLastCheck=0;
    outputSink.setReporter(reporter);
    outputSink.startWriterThreads();
    outputSinkStarted=true;
    Entry entry;
    Long lastFlushedSequenceId=-1L;
    ServerName serverName=DefaultWALProvider.getServerNameFromWALDirectoryName(logPath);
    failedServerName=(serverName == null) ? "" : serverName.getServerName();
    while ((entry=getNextLogLine(in,logPath,skipErrors)) != null) {
      byte[] region=entry.getKey().getEncodedRegionName();
      String encodedRegionNameAsStr=Bytes.toString(region);
      lastFlushedSequenceId=lastFlushedSequenceIds.get(encodedRegionNameAsStr);
      if (lastFlushedSequenceId == null) {
        if (this.distributedLogReplay) {
          RegionStoreSequenceIds ids=csm.getSplitLogWorkerCoordination().getRegionFlushedSequenceId(failedServerName,encodedRegionNameAsStr);
          if (ids != null) {
            lastFlushedSequenceId=ids.getLastFlushedSequenceId();
            if (LOG.isDebugEnabled()) {
              LOG.debug("DLR Last flushed sequenceid for " + encodedRegionNameAsStr + ": "+ TextFormat.shortDebugString(ids));
            }
          }
        }
 else         if (sequenceIdChecker != null) {
          RegionStoreSequenceIds ids=sequenceIdChecker.getLastSequenceId(region);
          Map<byte[],Long> maxSeqIdInStores=new TreeMap<byte[],Long>(Bytes.BYTES_COMPARATOR);
          for (          StoreSequenceId storeSeqId : ids.getStoreSequenceIdList()) {
            maxSeqIdInStores.put(storeSeqId.getFamilyName().toByteArray(),storeSeqId.getSequenceId());
          }
          regionMaxSeqIdInStores.put(encodedRegionNameAsStr,maxSeqIdInStores);
          lastFlushedSequenceId=ids.getLastFlushedSequenceId();
          if (LOG.isDebugEnabled()) {
            LOG.debug("DLS Last flushed sequenceid for " + encodedRegionNameAsStr + ": "+ TextFormat.shortDebugString(ids));
          }
        }
        if (lastFlushedSequenceId == null) {
          lastFlushedSequenceId=-1L;
        }
        lastFlushedSequenceIds.put(encodedRegionNameAsStr,lastFlushedSequenceId);
      }
      if (lastFlushedSequenceId >= entry.getKey().getSequenceId()) {
        editsSkipped++;
        continue;
      }
      entryBuffers.appendEntry(entry);
      editsCount++;
      int moreWritersFromLastCheck=this.getNumOpenWriters() - numOpenedFilesLastCheck;
      if (editsCount % interval == 0 || moreWritersFromLastCheck > numOpenedFilesBeforeReporting) {
        numOpenedFilesLastCheck=this.getNumOpenWriters();
        String countsStr=(editsCount - (editsSkipped + outputSink.getSkippedEdits())) + " edits, skipped " + editsSkipped+ " edits.";
        status.setStatus("Split " + countsStr);
        if (reporter != null && !reporter.progress()) {
          progress_failed=true;
          return false;
        }
      }
    }
  }
 catch (  InterruptedException ie) {
    IOException iie=new InterruptedIOException();
    iie.initCause(ie);
    throw iie;
  }
catch (  CorruptedLogFileException e) {
    LOG.warn("Could not parse, corrupted log file " + logPath,e);
    csm.getSplitLogWorkerCoordination().markCorrupted(rootDir,logfile.getPath().getName(),fs);
    isCorrupted=true;
  }
catch (  IOException e) {
    e=e instanceof RemoteException ? ((RemoteException)e).unwrapRemoteException() : e;
    throw e;
  }
 finally {
    LOG.debug("Finishing writing output logs and closing down.");
    try {
      if (null != in) {
        in.close();
      }
    }
 catch (    IOException exception) {
      LOG.warn("Could not close wal reader: " + exception.getMessage());
      LOG.debug("exception details",exception);
    }
    try {
      if (outputSinkStarted) {
        progress_failed=true;
        progress_failed=outputSink.finishWritingAndClose() == null;
      }
    }
  finally {
      String msg="Processed " + editsCount + " edits across "+ outputSink.getNumberOfRecoveredRegions()+ " regions; edits skipped="+ editsSkipped+ "; log file="+ logPath+ ", length="+ logfile.getLen()+ ", corrupted="+ isCorrupted+ ", progress failed="+ progress_failed;
      LOG.info(msg);
      status.markComplete(msg);
    }
  }
  return !progress_failed;
}
