{
  TableName tableName=TableName.valueOf("testBulkLoadWithParallelScan");
  final long l=System.currentTimeMillis();
  HBaseAdmin admin=new HBaseAdmin(TEST_UTIL.getConfiguration());
  createTable(admin,tableName);
  Scan scan=createScan();
  final HTable table=init(admin,l,scan,tableName);
  final Path hfilePath=writeToHFile(l,"/temp/testBulkLoadWithParallelScan/","/temp/testBulkLoadWithParallelScan/col/file",false);
  Configuration conf=TEST_UTIL.getConfiguration();
  conf.setBoolean("hbase.mapreduce.bulkload.assign.sequenceNumbers",true);
  final LoadIncrementalHFiles bulkload=new LoadIncrementalHFiles(conf);
  ResultScanner scanner=table.getScanner(scan);
  final CountDownLatch latch=new CountDownLatch(1);
  new Thread(){
    public void run(){
      try {
        Put put1=new Put(Bytes.toBytes("row5"));
        put1.add(new KeyValue(Bytes.toBytes("row5"),Bytes.toBytes("col"),Bytes.toBytes("q"),l,Bytes.toBytes("version0")));
        table.put(put1);
        table.flushCommits();
        bulkload.doBulkLoad(hfilePath,table);
        latch.countDown();
      }
 catch (      TableNotFoundException e) {
      }
catch (      IOException e) {
      }
    }
  }
.start();
  latch.await();
  Result result=scanner.next();
  scanAfterBulkLoad(scanner,result,"version1");
  scanner.close();
  table.close();
}
