{
  HBaseTestingUtility htu=new HBaseTestingUtility();
  final int DEFAULT_BLOCK_SIZE=1024;
  htu.getConfiguration().setLong("dfs.blocksize",DEFAULT_BLOCK_SIZE);
  MiniDFSCluster cluster=null;
  Path testFile=null;
  try {
    String hosts[]=new String[]{"host1","host2","host3"};
    cluster=htu.startMiniDFSCluster(hosts);
    cluster.waitActive();
    FileSystem fs=cluster.getFileSystem();
    testFile=new Path("/test1.txt");
    WriteDataToHDFS(fs,testFile,2 * DEFAULT_BLOCK_SIZE);
    final long maxTime=System.currentTimeMillis() + 2000;
    boolean ok;
    do {
      ok=true;
      FileStatus status=fs.getFileStatus(testFile);
      HDFSBlocksDistribution blocksDistribution=FSUtils.computeHDFSBlocksDistribution(fs,status,0,status.getLen());
      long uniqueBlocksTotalWeight=blocksDistribution.getUniqueBlocksTotalWeight();
      for (      String host : hosts) {
        long weight=blocksDistribution.getWeight(host);
        ok=(ok && uniqueBlocksTotalWeight == weight);
      }
    }
 while (!ok && System.currentTimeMillis() < maxTime);
    assertTrue(ok);
  }
  finally {
    htu.shutdownMiniDFSCluster();
  }
  try {
    String hosts[]=new String[]{"host1","host2","host3","host4"};
    cluster=htu.startMiniDFSCluster(hosts);
    cluster.waitActive();
    FileSystem fs=cluster.getFileSystem();
    testFile=new Path("/test2.txt");
    WriteDataToHDFS(fs,testFile,3 * DEFAULT_BLOCK_SIZE);
    final long maxTime=System.currentTimeMillis() + 2000;
    long weight;
    long uniqueBlocksTotalWeight;
    do {
      FileStatus status=fs.getFileStatus(testFile);
      HDFSBlocksDistribution blocksDistribution=FSUtils.computeHDFSBlocksDistribution(fs,status,0,status.getLen());
      uniqueBlocksTotalWeight=blocksDistribution.getUniqueBlocksTotalWeight();
      String tophost=blocksDistribution.getTopHosts().get(0);
      weight=blocksDistribution.getWeight(tophost);
    }
 while (uniqueBlocksTotalWeight != weight && System.currentTimeMillis() < maxTime);
    assertTrue(uniqueBlocksTotalWeight == weight);
  }
  finally {
    htu.shutdownMiniDFSCluster();
  }
  try {
    String hosts[]=new String[]{"host1","host2","host3","host4"};
    cluster=htu.startMiniDFSCluster(hosts);
    cluster.waitActive();
    FileSystem fs=cluster.getFileSystem();
    testFile=new Path("/test3.txt");
    WriteDataToHDFS(fs,testFile,DEFAULT_BLOCK_SIZE);
    final long maxTime=System.currentTimeMillis() + 2000;
    HDFSBlocksDistribution blocksDistribution;
    do {
      FileStatus status=fs.getFileStatus(testFile);
      blocksDistribution=FSUtils.computeHDFSBlocksDistribution(fs,status,0,status.getLen());
    }
 while (blocksDistribution.getTopHosts().size() != 3 && System.currentTimeMillis() < maxTime);
    assertEquals("Wrong number of hosts distributing blocks.",3,blocksDistribution.getTopHosts().size());
  }
  finally {
    htu.shutdownMiniDFSCluster();
  }
}
