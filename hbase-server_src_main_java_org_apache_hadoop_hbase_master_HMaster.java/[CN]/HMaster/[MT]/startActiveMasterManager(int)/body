{
  String backupZNode=ZKUtil.joinZNode(zooKeeper.backupMasterAddressesZNode,serverName.toString());
  LOG.info("Adding backup master ZNode " + backupZNode);
  if (!MasterAddressTracker.setMasterAddress(zooKeeper,backupZNode,serverName,infoPort)) {
    LOG.warn("Failed create of " + backupZNode + " by "+ serverName);
  }
  activeMasterManager.setInfoPort(infoPort);
  Threads.setDaemonThreadRunning(new Thread(new Runnable(){
    @Override public void run(){
      int timeout=conf.getInt(HConstants.ZK_SESSION_TIMEOUT,HConstants.DEFAULT_ZK_SESSION_TIMEOUT);
      if (conf.getBoolean(HConstants.MASTER_TYPE_BACKUP,HConstants.DEFAULT_MASTER_TYPE_BACKUP)) {
        LOG.debug("HMaster started in backup mode. " + "Stalling until master znode is written.");
        while (!activeMasterManager.hasActiveMaster()) {
          LOG.debug("Waiting for master address ZNode to be written " + "(Also watching cluster state node)");
          Threads.sleep(timeout);
        }
      }
      MonitoredTask status=TaskMonitor.get().createStatus("Master startup");
      status.setDescription("Master startup");
      try {
        if (activeMasterManager.blockUntilBecomingActiveMaster(timeout,status)) {
          finishActiveMasterInitialization(status);
        }
      }
 catch (      Throwable t) {
        status.setStatus("Failed to become active: " + t.getMessage());
        LOG.fatal("Failed to become active master",t);
        if (t instanceof NoClassDefFoundError && t.getMessage().contains("org/apache/hadoop/hdfs/protocol/HdfsConstants$SafeModeAction")) {
          abort("HBase is having a problem with its Hadoop jars.  You may need to " + "recompile HBase against Hadoop version " + org.apache.hadoop.util.VersionInfo.getVersion() + " or change your hadoop jars to start properly",t);
        }
 else {
          abort("Unhandled exception. Starting shutdown.",t);
        }
      }
 finally {
        status.cleanup();
      }
    }
  }
,getServerName().toShortString() + ".activeMasterManager"));
}
