{
  CompletionService<Integer> pool=new ExecutorCompletionService<Integer>(this.exec);
  List<Entry> entries=replicateContext.getEntries();
  String walGroupId=replicateContext.getWalGroupId();
  int sleepMultiplier=1;
  int numReplicated=0;
  if (!peersSelected && this.isRunning()) {
    connectToPeers();
    peersSelected=true;
  }
  int numSinks=replicationSinkMgr.getNumSinks();
  if (numSinks == 0) {
    LOG.warn("No replication sinks found, returning without replicating. The source should retry" + " with the same set of edits.");
    return false;
  }
  int n=Math.min(Math.min(this.maxThreads,entries.size() / 100 + 1),numSinks);
  List<List<Entry>> entryLists=new ArrayList<List<Entry>>(n);
  if (n == 1) {
    entryLists.add(entries);
  }
 else {
    for (int i=0; i < n; i++) {
      entryLists.add(new ArrayList<Entry>(entries.size() / n + 1));
    }
    for (    Entry e : entries) {
      entryLists.get(Math.abs(Bytes.hashCode(e.getKey().getEncodedRegionName()) % n)).add(e);
    }
  }
  while (this.isRunning() && !exec.isShutdown()) {
    if (!isPeerEnabled()) {
      if (sleepForRetries("Replication is disabled",sleepMultiplier)) {
        sleepMultiplier++;
      }
      continue;
    }
    try {
      if (LOG.isTraceEnabled()) {
        LOG.trace("Replicating " + entries.size() + " entries of total size "+ replicateContext.getSize());
      }
      int futures=0;
      for (int i=0; i < entryLists.size(); i++) {
        if (!entryLists.get(i).isEmpty()) {
          if (LOG.isTraceEnabled()) {
            LOG.trace("Submitting " + entryLists.get(i).size() + " entries of total size "+ replicateContext.getSize());
          }
          pool.submit(createReplicator(entryLists.get(i),i));
          futures++;
        }
      }
      IOException iox=null;
      for (int i=0; i < futures; i++) {
        try {
          Future<Integer> f=pool.take();
          int index=f.get().intValue();
          int batchSize=entryLists.get(index).size();
          entryLists.set(index,Collections.<Entry>emptyList());
          numReplicated+=batchSize;
        }
 catch (        InterruptedException ie) {
          iox=new IOException(ie);
        }
catch (        ExecutionException ee) {
          iox=(IOException)ee.getCause();
        }
      }
      if (iox != null) {
        throw iox;
      }
      if (numReplicated != entries.size()) {
        LOG.warn("The number of edits replicated is different from the number received," + " failing for now.");
        return false;
      }
      this.metrics.setAgeOfLastShippedOp(entries.get(entries.size() - 1).getKey().getWriteTime(),walGroupId);
      return true;
    }
 catch (    IOException ioe) {
      this.metrics.refreshAgeOfLastShippedOp(walGroupId);
      if (ioe instanceof RemoteException) {
        ioe=((RemoteException)ioe).unwrapRemoteException();
        LOG.warn("Can't replicate because of an error on the remote cluster: ",ioe);
        if (ioe instanceof TableNotFoundException) {
          if (sleepForRetries("A table is missing in the peer cluster. " + "Replication cannot proceed without losing data.",sleepMultiplier)) {
            sleepMultiplier++;
          }
        }
      }
 else {
        if (ioe instanceof SocketTimeoutException) {
          sleepForRetries("Encountered a SocketTimeoutException. Since the " + "call to the remote cluster timed out, which is usually " + "caused by a machine failure or a massive slowdown",this.socketTimeoutMultiplier);
        }
 else         if (ioe instanceof ConnectException) {
          LOG.warn("Peer is unavailable, rechecking all sinks: ",ioe);
          replicationSinkMgr.chooseSinks();
        }
 else {
          LOG.warn("Can't replicate because of a local or network error: ",ioe);
        }
      }
      if (sleepForRetries("Since we are unable to replicate",sleepMultiplier)) {
        sleepMultiplier++;
      }
    }
  }
  return false;
}
