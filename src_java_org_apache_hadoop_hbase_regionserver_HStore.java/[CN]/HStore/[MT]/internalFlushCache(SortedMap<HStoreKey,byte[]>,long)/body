{
  long flushed=0;
  if (cache.size() == 0) {
    return false;
  }
synchronized (flushLock) {
    long now=System.currentTimeMillis();
    HStoreFile flushedFile=new HStoreFile(conf,fs,basedir,info.getEncodedName(),family.getName(),-1L,null);
    MapFile.Writer out=flushedFile.getWriter(this.fs,this.compression,this.family.isBloomfilter(),cache.size());
    out.setIndexInterval(family.getMapFileIndexInterval());
    int entries=0;
    try {
      for (      Map.Entry<HStoreKey,byte[]> es : cache.entrySet()) {
        HStoreKey curkey=es.getKey();
        byte[] bytes=es.getValue();
        if (HStoreKey.matchingFamily(this.family.getName(),curkey.getColumn())) {
          if (ttl == HConstants.FOREVER || now < curkey.getTimestamp() + ttl) {
            entries++;
            out.append(curkey,new ImmutableBytesWritable(bytes));
            flushed+=curkey.getSize() + (bytes == null ? 0 : bytes.length);
          }
 else {
            if (LOG.isDebugEnabled()) {
              LOG.debug("internalFlushCache: " + curkey + ": expired, skipped");
            }
          }
        }
      }
    }
  finally {
      out.close();
    }
    long newStoreSize=flushedFile.length();
    storeSize+=newStoreSize;
    flushedFile.writeInfo(fs,logCacheFlushId);
    updateReaders(logCacheFlushId,flushedFile);
    if (LOG.isDebugEnabled()) {
      LOG.debug("Added " + FSUtils.getPath(flushedFile.getMapFilePath()) + " with "+ entries+ " entries, sequence id "+ logCacheFlushId+ ", data size "+ StringUtils.humanReadableInt(flushed)+ ", file size "+ StringUtils.humanReadableInt(newStoreSize));
    }
  }
  return storefiles.size() >= compactionThreshold;
}
