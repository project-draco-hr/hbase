{
  if (reconstructionLog == null || !fs.exists(reconstructionLog)) {
    return;
  }
  long maxSeqIdInLog=-1;
  TreeMap<HStoreKey,byte[]> reconstructedCache=new TreeMap<HStoreKey,byte[]>();
  SequenceFile.Reader logReader=new SequenceFile.Reader(this.fs,reconstructionLog,this.conf);
  try {
    HLogKey key=new HLogKey();
    HLogEdit val=new HLogEdit();
    long skippedEdits=0;
    while (logReader.next(key,val)) {
      maxSeqIdInLog=Math.max(maxSeqIdInLog,key.getLogSeqNum());
      if (key.getLogSeqNum() <= maxSeqID) {
        skippedEdits++;
        continue;
      }
      if (skippedEdits > 0 && LOG.isDebugEnabled()) {
        LOG.debug("Skipped " + skippedEdits + " edits because sequence id <= "+ maxSeqID);
      }
      Text column=val.getColumn();
      if (column.equals(HLog.METACOLUMN) || !key.getRegionName().equals(info.getRegionName()) || !HStoreKey.extractFamily(column).equals(family.getFamilyName())) {
        continue;
      }
      HStoreKey k=new HStoreKey(key.getRow(),column,val.getTimestamp());
      if (LOG.isDebugEnabled()) {
        LOG.debug("Applying edit <" + k.toString() + "="+ val.toString()+ ">");
      }
      reconstructedCache.put(k,val.getVal());
    }
  }
  finally {
    logReader.close();
  }
  if (reconstructedCache.size() > 0) {
    if (LOG.isDebugEnabled()) {
      LOG.debug("flushing reconstructionCache");
    }
    internalFlushCache(reconstructedCache,maxSeqIdInLog + 1);
  }
}
