{
synchronized (compactLock) {
    long maxId=-1;
    int nrows=-1;
    List<HStoreFile> filesToCompact=null;
synchronized (storefiles) {
      if (this.storefiles.size() <= 0) {
        return null;
      }
      filesToCompact=new ArrayList<HStoreFile>(this.storefiles.values());
      maxId=this.storefiles.lastKey().longValue();
    }
    long lastMajorCompaction=0L;
    if (!majorCompaction) {
      Path mapdir=HStoreFile.getMapDir(basedir,info.getEncodedName(),family.getName());
      long lowTimestamp=getLowestTimestamp(fs,mapdir);
      if (LOG.isDebugEnabled() && lowTimestamp > 0l) {
        LOG.debug("Time since last major compaction on store " + this.storeNameStr + ": "+ ((System.currentTimeMillis() - lowTimestamp) / 1000)+ " seconds");
      }
      lastMajorCompaction=System.currentTimeMillis() - lowTimestamp;
      if (lowTimestamp < (System.currentTimeMillis() - majorCompactionTime) && lowTimestamp > 0l) {
        if (LOG.isDebugEnabled()) {
          LOG.debug("Major compaction triggered on store: " + this.storeNameStr + ". Time since last major compaction: "+ ((System.currentTimeMillis() - lowTimestamp) / 1000)+ " seconds");
        }
        majorCompaction=true;
      }
    }
    if (!majorCompaction && !hasReferences(filesToCompact) && filesToCompact.size() < compactionThreshold) {
      return checkSplit();
    }
    if (!fs.exists(compactionDir) && !fs.mkdirs(compactionDir)) {
      LOG.warn("Mkdir on " + compactionDir.toString() + " failed");
      return checkSplit();
    }
    int countOfFiles=filesToCompact.size();
    long totalSize=0;
    long[] fileSizes=new long[countOfFiles];
    long skipped=0;
    int point=0;
    for (int i=0; i < countOfFiles; i++) {
      HStoreFile file=filesToCompact.get(i);
      Path path=file.getMapFilePath();
      int len=0;
      for (      FileStatus fstatus : fs.listStatus(path)) {
        len+=fstatus.getLen();
      }
      fileSizes[i]=len;
      totalSize+=len;
    }
    if (!majorCompaction && !hasReferences(filesToCompact)) {
      for (point=0; point < compactionThreshold - 1; point++) {
        if (fileSizes[point] < fileSizes[point + 1] * 2 && maxFilesToCompact < (countOfFiles - point)) {
          break;
        }
        skipped+=fileSizes[point];
      }
      filesToCompact=new ArrayList<HStoreFile>(filesToCompact.subList(point,countOfFiles));
      if (filesToCompact.size() <= 1) {
        if (LOG.isDebugEnabled()) {
          LOG.debug("Skipped compaction of 1 file; compaction size of " + this.storeNameStr + ": "+ StringUtils.humanReadableInt(totalSize)+ "; Skipped "+ point+ " files, size: "+ skipped);
        }
        return checkSplit();
      }
      if (LOG.isDebugEnabled()) {
        LOG.debug("Compaction size of " + this.storeNameStr + ": "+ StringUtils.humanReadableInt(totalSize)+ "; Skipped "+ point+ " files , size: "+ skipped);
      }
    }
    List<MapFile.Reader> rdrs=new ArrayList<MapFile.Reader>();
    for (    HStoreFile file : filesToCompact) {
      try {
        HStoreFile.BloomFilterMapFile.Reader reader=file.getReader(fs,false,false);
        rdrs.add(reader);
        if (this.family.isBloomfilter()) {
          nrows+=reader.getBloomFilterSize();
        }
      }
 catch (      IOException e) {
        LOG.warn("Failed with " + e.toString() + ": "+ file.toString());
        closeCompactionReaders(rdrs);
        throw e;
      }
    }
    HStoreFile compactedOutputFile=new HStoreFile(conf,fs,this.compactionDir,info.getEncodedName(),family.getName(),-1L,null);
    if (LOG.isDebugEnabled()) {
      LOG.debug("started compaction of " + rdrs.size() + " files into "+ FSUtils.getPath(compactedOutputFile.getMapFilePath()));
    }
    MapFile.Writer writer=compactedOutputFile.getWriter(this.fs,this.compression,this.family.isBloomfilter(),nrows);
    writer.setIndexInterval(family.getMapFileIndexInterval());
    try {
      compact(writer,rdrs,majorCompaction);
    }
  finally {
      writer.close();
    }
    compactedOutputFile.writeInfo(fs,maxId);
    completeCompaction(filesToCompact,compactedOutputFile);
    if (LOG.isDebugEnabled()) {
      LOG.debug("Completed compaction of " + this.storeNameStr + " store size is "+ StringUtils.humanReadableInt(storeSize)+ (majorCompaction ? "" : "; time since last major compaction: " + (lastMajorCompaction / 1000) + " seconds"));
    }
  }
  return checkSplit();
}
