{
  Stat stat=new Stat();
  long t=-1;
  byte[] data;
synchronized (grabTaskLock) {
    currentTask=path;
    workerInGrabTask=true;
    if (Thread.interrupted()) {
      return;
    }
  }
  try {
    try {
      if ((data=ZKUtil.getDataNoWatch(this.watcher,path,stat)) == null) {
        SplitLogCounters.tot_wkr_failed_to_grab_task_no_data.incrementAndGet();
        return;
      }
    }
 catch (    KeeperException e) {
      LOG.warn("Failed to get data for znode " + path,e);
      SplitLogCounters.tot_wkr_failed_to_grab_task_exception.incrementAndGet();
      return;
    }
    SplitLogTask slt;
    try {
      slt=SplitLogTask.parseFrom(data);
    }
 catch (    DeserializationException e) {
      LOG.warn("Failed parse data for znode " + path,e);
      SplitLogCounters.tot_wkr_failed_to_grab_task_exception.incrementAndGet();
      return;
    }
    if (!slt.isUnassigned()) {
      SplitLogCounters.tot_wkr_failed_to_grab_task_owned.incrementAndGet();
      return;
    }
    currentVersion=attemptToOwnTask(true,watcher,serverName,path,stat.getVersion());
    if (currentVersion < 0) {
      SplitLogCounters.tot_wkr_failed_to_grab_task_lost_race.incrementAndGet();
      return;
    }
    if (ZKSplitLog.isRescanNode(watcher,currentTask)) {
      HLogSplitterHandler.endTask(watcher,new SplitLogTask.Done(this.serverName),SplitLogCounters.tot_wkr_task_acquired_rescan,currentTask,currentVersion);
      return;
    }
    LOG.info("worker " + serverName + " acquired task "+ path);
    SplitLogCounters.tot_wkr_task_acquired.incrementAndGet();
    getDataSetWatchAsync();
    submitTask(path,currentVersion,this.report_period);
    try {
      int sleepTime=RandomUtils.nextInt(500) + 500;
      Thread.sleep(sleepTime);
    }
 catch (    InterruptedException e) {
      LOG.warn("Interrupted while yielding for other region servers",e);
      Thread.currentThread().interrupt();
    }
  }
  finally {
synchronized (grabTaskLock) {
      workerInGrabTask=false;
      Thread.interrupted();
    }
  }
}
