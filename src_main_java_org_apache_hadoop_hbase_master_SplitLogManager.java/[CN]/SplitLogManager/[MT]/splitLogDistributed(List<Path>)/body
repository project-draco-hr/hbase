{
  MonitoredTask status=TaskMonitor.get().createStatus("Doing distributed log split in " + logDirs);
  FileStatus[] logfiles=getFileList(logDirs);
  status.setStatus("Checking directory contents...");
  LOG.debug("Scheduling batch of logs to split");
  SplitLogCounters.tot_mgr_log_split_batch_start.incrementAndGet();
  LOG.info("started splitting logs in " + logDirs);
  long t=EnvironmentEdgeManager.currentTimeMillis();
  long totalSize=0;
  TaskBatch batch=new TaskBatch();
  for (  FileStatus lf : logfiles) {
    totalSize+=lf.getLen();
    if (enqueueSplitTask(lf.getPath().toString(),batch) == false) {
      throw new IOException("duplicate log split scheduled for " + lf.getPath());
    }
  }
  waitForSplittingCompletion(batch,status);
  if (batch.done != batch.installed) {
    batch.isDead=true;
    SplitLogCounters.tot_mgr_log_split_batch_err.incrementAndGet();
    LOG.warn("error while splitting logs in " + logDirs + " installed = "+ batch.installed+ " but only "+ batch.done+ " done");
    throw new IOException("error or interrupt while splitting logs in " + logDirs + " Task = "+ batch);
  }
  for (  Path logDir : logDirs) {
    status.setStatus("Cleaning up log directory...");
    try {
      if (fs.exists(logDir) && !fs.delete(logDir,false)) {
        LOG.warn("Unable to delete log src dir. Ignoring. " + logDir);
      }
    }
 catch (    IOException ioe) {
      FileStatus[] files=fs.listStatus(logDir);
      if (files != null && files.length > 0) {
        LOG.warn("returning success without actually splitting and " + "deleting all the log files in path " + logDir);
      }
 else {
        LOG.warn("Unable to delete log src dir. Ignoring. " + logDir,ioe);
      }
    }
    SplitLogCounters.tot_mgr_log_split_batch_success.incrementAndGet();
  }
  String msg="finished splitting (more than or equal to) " + totalSize + " bytes in "+ batch.installed+ " log files in "+ logDirs+ " in "+ (EnvironmentEdgeManager.currentTimeMillis() - t)+ "ms";
  status.markComplete(msg);
  LOG.info(msg);
  return totalSize;
}
