{
  LOG.info("testConcurrentSplitLogAndReplayRecoverEdit");
  String regionName="r0";
  final Path regiondir=new Path(TABLEDIR,regionName);
  REGIONS=new ArrayList<String>();
  REGIONS.add(regionName);
  generateHLogs(-1);
  HLogFactory.createHLog(fs,regiondir,regionName,conf);
  FileStatus[] logfiles=fs.listStatus(HLOGDIR);
  assertTrue("There should be some log file",logfiles != null && logfiles.length > 0);
  HLogSplitter logSplitter=new HLogSplitter(conf,HBASEDIR,fs,null,null,null,this.mode){
    protected HLog.Writer createWriter(    FileSystem fs,    Path logfile,    Configuration conf) throws IOException {
      HLog.Writer writer=HLogFactory.createRecoveredEditsWriter(fs,logfile,conf);
      NavigableSet<Path> files=HLogUtil.getSplitEditFilesSorted(fs,regiondir);
      if (files != null && !files.isEmpty()) {
        for (        Path file : files) {
          if (!this.fs.delete(file,false)) {
            LOG.error("Failed delete of " + file);
          }
 else {
            LOG.debug("Deleted recovered.edits file=" + file);
          }
        }
      }
      return writer;
    }
  }
;
  try {
    logSplitter.splitLogFile(logfiles[0],null);
  }
 catch (  IOException e) {
    LOG.info(e);
    Assert.fail("Throws IOException when spliting " + "log, it is most likely because writing file does not " + "exist which is caused by concurrent replayRecoveredEditsIfAny()");
  }
  if (fs.exists(CORRUPTDIR)) {
    if (fs.listStatus(CORRUPTDIR).length > 0) {
      Assert.fail("There are some corrupt logs, " + "it is most likely caused by concurrent replayRecoveredEditsIfAny()");
    }
  }
}
