{
  if (reconstructionLog == null || !this.fs.exists(reconstructionLog)) {
    return;
  }
  FileStatus[] stats=this.fs.listStatus(reconstructionLog);
  if (stats == null || stats.length == 0) {
    LOG.warn("Passed reconstruction log " + reconstructionLog + " is zero-length");
    return;
  }
  long maxSeqIdInLog=-1;
  ConcurrentSkipListSet<KeyValue> reconstructedCache=Memcache.createSet(this.comparator);
  SequenceFile.Reader logReader=new SequenceFile.Reader(this.fs,reconstructionLog,this.conf);
  try {
    HLogKey key=new HLogKey();
    KeyValue val=new KeyValue();
    long skippedEdits=0;
    long editsCount=0;
    int reportInterval=this.conf.getInt("hbase.hstore.report.interval.edits",2000);
    while (logReader.next(key,val)) {
      maxSeqIdInLog=Math.max(maxSeqIdInLog,key.getLogSeqNum());
      if (key.getLogSeqNum() <= maxSeqID) {
        skippedEdits++;
        continue;
      }
      if (val.matchingColumnNoDelimiter(HLog.METACOLUMN,HLog.METACOLUMN.length - 1) || !Bytes.equals(key.getRegionName(),regioninfo.getRegionName()) || !val.matchingFamily(family.getName())) {
        continue;
      }
      reconstructedCache.add(val);
      editsCount++;
      if (reporter != null && (editsCount % reportInterval) == 0) {
        reporter.progress();
      }
    }
    if (LOG.isDebugEnabled()) {
      LOG.debug("Applied " + editsCount + ", skipped "+ skippedEdits+ " because sequence id <= "+ maxSeqID);
    }
  }
  finally {
    logReader.close();
  }
  if (reconstructedCache.size() > 0) {
    if (LOG.isDebugEnabled()) {
      LOG.debug("flushing reconstructionCache");
    }
    internalFlushCache(reconstructedCache,maxSeqIdInLog + 1);
  }
}
