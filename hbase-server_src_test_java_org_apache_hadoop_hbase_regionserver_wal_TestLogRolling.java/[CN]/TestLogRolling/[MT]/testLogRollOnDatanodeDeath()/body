{
  TEST_UTIL.ensureSomeRegionServersAvailable(2);
  assertTrue("This test requires HLog file replication set to 2.",fs.getDefaultReplication(TEST_UTIL.getDataTestDirOnTestFS()) == 2);
  LOG.info("Replication=" + fs.getDefaultReplication(TEST_UTIL.getDataTestDirOnTestFS()));
  this.server=cluster.getRegionServer(0);
  this.log=server.getWAL();
  String tableName=getName();
  HTableDescriptor desc=new HTableDescriptor(TableName.valueOf(tableName));
  desc.addFamily(new HColumnDescriptor(HConstants.CATALOG_FAMILY));
  admin.createTable(desc);
  Table table=new HTable(TEST_UTIL.getConfiguration(),tableName);
  assertTrue(table.isAutoFlush());
  server=TEST_UTIL.getRSForFirstRegionInTable(Bytes.toBytes(tableName));
  this.log=server.getWAL();
  assertTrue("Need HDFS-826 for this test",((FSHLog)log).canGetCurReplicas());
  assertTrue("Need append support for this test",FSUtils.isAppendSupported(TEST_UTIL.getConfiguration()));
  List<DataNode> existingNodes=dfsCluster.getDataNodes();
  int numDataNodes=3;
  dfsCluster.startDataNodes(TEST_UTIL.getConfiguration(),numDataNodes,true,null,null);
  List<DataNode> allNodes=dfsCluster.getDataNodes();
  for (int i=allNodes.size() - 1; i >= 0; i--) {
    if (existingNodes.contains(allNodes.get(i))) {
      dfsCluster.stopDataNode(i);
    }
  }
  assertTrue("DataNodes " + dfsCluster.getDataNodes().size() + " default replication "+ fs.getDefaultReplication(TEST_UTIL.getDataTestDirOnTestFS()),dfsCluster.getDataNodes().size() >= fs.getDefaultReplication(TEST_UTIL.getDataTestDirOnTestFS()) + 1);
  writeData(table,2);
  long curTime=System.currentTimeMillis();
  long oldFilenum=((FSHLog)log).getFilenum();
  assertTrue("Log should have a timestamp older than now",curTime > oldFilenum && oldFilenum != -1);
  assertTrue("The log shouldn't have rolled yet",oldFilenum == ((FSHLog)log).getFilenum());
  final DatanodeInfo[] pipeline=getPipeline(log);
  assertTrue(pipeline.length == fs.getDefaultReplication(TEST_UTIL.getDataTestDirOnTestFS()));
  assertTrue(dfsCluster.stopDataNode(pipeline[0].getName()) != null);
  writeData(table,2);
  long newFilenum=((FSHLog)log).getFilenum();
  assertTrue("Missing datanode should've triggered a log roll",newFilenum > oldFilenum && newFilenum > curTime);
  writeData(table,3);
  assertTrue("The log should not roll again.",((FSHLog)log).getFilenum() == newFilenum);
  assertTrue(dfsCluster.stopDataNode(pipeline[1].getName()) != null);
  batchWriteAndWait(table,3,false,14000);
  assertTrue("LowReplication Roller should've been disabled, current replication=" + ((FSHLog)log).getLogReplication(),!log.isLowReplicationRollEnabled());
  dfsCluster.startDataNodes(TEST_UTIL.getConfiguration(),1,true,null,null);
  log.rollWriter(true);
  batchWriteAndWait(table,13,true,10000);
  assertTrue("New log file should have the default replication instead of " + ((FSHLog)log).getLogReplication(),((FSHLog)log).getLogReplication() == fs.getDefaultReplication(TEST_UTIL.getDataTestDirOnTestFS()));
  assertTrue("LowReplication Roller should've been enabled",log.isLowReplicationRollEnabled());
}
