{
  LOG.info("Starting testLogRollOnPipelineRestart");
  assertTrue("This test requires HLog file replication.",fs.getDefaultReplication() > 1);
  LOG.info("Replication=" + fs.getDefaultReplication());
  new HTable(TEST_UTIL.getConfiguration(),HConstants.META_TABLE_NAME);
  this.server=cluster.getRegionServer(0);
  this.log=server.getWAL();
  String tableName=getName();
  HTableDescriptor desc=new HTableDescriptor(tableName);
  desc.addFamily(new HColumnDescriptor(HConstants.CATALOG_FAMILY));
  admin.createTable(desc);
  HTable table=new HTable(TEST_UTIL.getConfiguration(),tableName);
  server=TEST_UTIL.getRSForFirstRegionInTable(Bytes.toBytes(tableName));
  this.log=server.getWAL();
  final List<Path> paths=new ArrayList<Path>();
  final List<Integer> preLogRolledCalled=new ArrayList<Integer>();
  paths.add(log.computeFilename());
  log.registerWALActionsListener(new WALActionsListener(){
    @Override public void preLogRoll(    Path oldFile,    Path newFile){
      preLogRolledCalled.add(new Integer(1));
    }
    @Override public void postLogRoll(    Path oldFile,    Path newFile){
      paths.add(newFile);
    }
    @Override public void preLogArchive(    Path oldFile,    Path newFile){
    }
    @Override public void postLogArchive(    Path oldFile,    Path newFile){
    }
    @Override public void logRollRequested(){
    }
    @Override public void logCloseRequested(){
    }
    @Override public void visitLogEntryBeforeWrite(    HRegionInfo info,    HLogKey logKey,    WALEdit logEdit){
    }
    @Override public void visitLogEntryBeforeWrite(    HTableDescriptor htd,    HLogKey logKey,    WALEdit logEdit){
    }
  }
);
  assertTrue("Need HDFS-826 for this test",log.canGetCurReplicas());
  assertTrue("Need append support for this test",FSUtils.isAppendSupported(TEST_UTIL.getConfiguration()));
  writeData(table,1002);
  table.setAutoFlush(true);
  long curTime=System.currentTimeMillis();
  long oldFilenum=log.getFilenum();
  assertTrue("Log should have a timestamp older than now",curTime > oldFilenum && oldFilenum != -1);
  assertTrue("The log shouldn't have rolled yet",oldFilenum == log.getFilenum());
  dfsCluster.restartDataNodes();
  Thread.sleep(10000);
  dfsCluster.waitActive();
  LOG.info("Data Nodes restarted");
  writeData(table,1003);
  long newFilenum=log.getFilenum();
  assertTrue("Missing datanode should've triggered a log roll",newFilenum > oldFilenum && newFilenum > curTime);
  writeData(table,1004);
  dfsCluster.restartDataNodes();
  Thread.sleep(10000);
  dfsCluster.waitActive();
  LOG.info("Data Nodes restarted");
  writeData(table,1005);
  log.rollWriter(true);
  assertTrue(preLogRolledCalled.size() == 1);
  Set<String> loggedRows=new HashSet<String>();
  for (  Path p : paths) {
    LOG.debug("Reading HLog " + FSUtils.getPath(p));
    HLog.Reader reader=null;
    try {
      reader=HLog.getReader(fs,p,TEST_UTIL.getConfiguration());
      HLog.Entry entry;
      while ((entry=reader.next()) != null) {
        LOG.debug("#" + entry.getKey().getLogSeqNum() + ": "+ entry.getEdit().getKeyValues());
        for (        KeyValue kv : entry.getEdit().getKeyValues()) {
          loggedRows.add(Bytes.toStringBinary(kv.getRow()));
        }
      }
    }
 catch (    EOFException e) {
      LOG.debug("EOF reading file " + FSUtils.getPath(p));
    }
 finally {
      if (reader != null)       reader.close();
    }
  }
  assertTrue(loggedRows.contains("row1002"));
  assertTrue(loggedRows.contains("row1003"));
  assertTrue(loggedRows.contains("row1004"));
  assertTrue(loggedRows.contains("row1005"));
  List<HRegion> regions=new ArrayList<HRegion>(server.getOnlineRegionsLocalContext());
  for (  HRegion r : regions) {
    r.flushcache();
  }
  ResultScanner scanner=table.getScanner(new Scan());
  try {
    for (int i=2; i <= 5; i++) {
      Result r=scanner.next();
      assertNotNull(r);
      assertFalse(r.isEmpty());
      assertEquals("row100" + i,Bytes.toString(r.getRow()));
    }
  }
  finally {
    scanner.close();
  }
}
