{
  if (errorMsg != null && errorMsg.length() > 0) {
    System.err.println("ERROR: " + errorMsg);
  }
  String usage="Usage: " + NAME + " -D"+ COLUMNS_CONF_KEY+ "=a,b,c <tablename> <inputdir>\n"+ "\n"+ "Imports the given input directory of TSV data into the specified table.\n"+ "\n"+ "The column names of the TSV data must be specified using the -D"+ COLUMNS_CONF_KEY+ "\n"+ "option. This option takes the form of comma-separated column names, where each\n"+ "column name is either a simple column family, or a columnfamily:qualifier. The special\n"+ "column name "+ TsvParser.ROWKEY_COLUMN_SPEC+ " is used to designate that this column should be used\n"+ "as the row key for each imported record. You must specify exactly one column\n"+ "to be the row key, and you must specify a column name for every column that exists in the\n"+ "input data. Another special column"+ TsvParser.TIMESTAMPKEY_COLUMN_SPEC+ " designates that this column should be\n"+ "used as timestamp for each record. Unlike "+ TsvParser.ROWKEY_COLUMN_SPEC+ ", "+ TsvParser.TIMESTAMPKEY_COLUMN_SPEC+ " is optional.\n"+ "You must specify at most one column as timestamp key for each imported record.\n"+ "Record with invalid timestamps (blank, non-numeric) will be treated as bad record.\n"+ "Note: if you use this option, then '"+ TIMESTAMP_CONF_KEY+ "' option will be ignored.\n"+ "\n"+ TsvParser.ATTRIBUTES_COLUMN_SPEC+ " can be used to specify Operation Attributes per record.\n"+ " Should be specified as key=>value where "+ TsvParser.DEFAULT_ATTRIBUTES_COLUMN_INDEX+ " is used \n"+ " as the seperator.  Note that more than one OperationAttributes can be specified.\n"+ "By default importtsv will load data directly into HBase. To instead generate\n"+ "HFiles of data to prepare for a bulk data load, pass the option:\n"+ "  -D"+ BULK_OUTPUT_CONF_KEY+ "=/path/for/output\n"+ "  Note: if you do not use this option, then the target table must already exist in HBase\n"+ "\n"+ "Other options that may be specified with -D include:\n"+ "  -D"+ SKIP_LINES_CONF_KEY+ "=false - fail if encountering an invalid line\n"+ "  '-D"+ SEPARATOR_CONF_KEY+ "=|' - eg separate on pipes instead of tabs\n"+ "  -D"+ TIMESTAMP_CONF_KEY+ "=currentTimeAsLong - use the specified timestamp for the import\n"+ "  -D"+ MAPPER_CONF_KEY+ "=my.Mapper - A user-defined Mapper to use instead of "+ DEFAULT_MAPPER.getName()+ "\n"+ "  -D"+ JOB_NAME_CONF_KEY+ "=jobName - use the specified mapreduce job name for the import\n"+ "  -D"+ CREATE_TABLE_CONF_KEY+ "=no - can be used to avoid creation of table by this tool\n"+ "  Note: if you set this to 'no', then the target table must already exist in HBase\n"+ "  -D"+ NO_STRICT_COL_FAMILY+ "=true - ignore column family check in hbase table. "+ "Default is false\n\n"+ "For performance consider the following options:\n"+ "  -Dmapreduce.map.speculative=false\n"+ "  -Dmapreduce.reduce.speculative=false";
  System.err.println(usage);
}
