{
  if (this.writer != null && this.numEntries.get() <= 0) {
    return null;
  }
  byte[][] regionsToFlush=null;
  this.cacheFlushLock.lock();
  try {
    if (closed) {
      return regionsToFlush;
    }
synchronized (updateLock) {
      Path oldFile=cleanupCurrentWriter(this.filenum);
      this.filenum=System.currentTimeMillis();
      Path newPath=computeFilename(this.filenum);
      this.writer=createWriter(fs,newPath,HBaseConfiguration.create(conf));
      this.initialReplication=fs.getFileStatus(newPath).getReplication();
      this.hdfs_out=null;
      if (this.writer instanceof SequenceFileLogWriter) {
        this.hdfs_out=((SequenceFileLogWriter)this.writer).getDFSCOutputStream();
      }
      LOG.info((oldFile != null ? "Roll " + FSUtils.getPath(oldFile) + ", entries="+ this.numEntries.get()+ ", filesize="+ this.fs.getFileStatus(oldFile).getLen()+ ". " : "") + "New hlog " + FSUtils.getPath(newPath));
      if (this.outputfiles.size() > 0) {
        if (this.lastSeqWritten.size() <= 0) {
          LOG.debug("Last sequence written is empty. Deleting all old hlogs");
          for (          Map.Entry<Long,Path> e : this.outputfiles.entrySet()) {
            archiveLogFile(e.getValue(),e.getKey());
          }
          this.outputfiles.clear();
        }
 else {
          regionsToFlush=cleanOldLogs();
        }
      }
      this.numEntries.set(0);
    }
  }
  finally {
    this.cacheFlushLock.unlock();
  }
  return regionsToFlush;
}
