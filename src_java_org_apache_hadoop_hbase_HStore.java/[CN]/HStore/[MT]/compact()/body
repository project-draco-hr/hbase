{
synchronized (compactLock) {
    Path curCompactStore=getCompactionDir();
    if (LOG.isDebugEnabled()) {
      LOG.debug("started compaction of " + storefiles.size() + " files using "+ curCompactStore.toString());
    }
    if (this.fs.exists(curCompactStore)) {
      Path[] toRemove=this.fs.listPaths(new Path[]{curCompactStore});
      for (int i=0; i < toRemove.length; i++) {
        this.fs.delete(toRemove[i]);
      }
    }
    List<HStoreFile> filesToCompact=new ArrayList<HStoreFile>(this.storefiles.values());
    Collections.reverse(filesToCompact);
    if (filesToCompact.size() < 1 || (filesToCompact.size() == 1 && !filesToCompact.get(0).isReference())) {
      if (LOG.isDebugEnabled()) {
        LOG.debug("nothing to compact for " + this.storeName);
      }
      return false;
    }
    if (!fs.exists(curCompactStore) && !fs.mkdirs(curCompactStore)) {
      LOG.warn("Mkdir on " + curCompactStore.toString() + " failed");
      return false;
    }
    HStoreFile compactedOutputFile=new HStoreFile(conf,this.compactionDir,encodedRegionName,familyName,-1);
    MapFile.Writer compactedOut=compactedOutputFile.getWriter(this.fs,this.compression,this.bloomFilter);
    try {
      compactHStoreFiles(compactedOut,filesToCompact);
    }
  finally {
      compactedOut.close();
    }
    long maxId=getMaxSequenceId(filesToCompact);
    compactedOutputFile.writeInfo(fs,maxId);
    Path filesToReplace=new Path(curCompactStore,COMPACTION_TO_REPLACE);
    FSDataOutputStream out=fs.create(filesToReplace);
    try {
      out.writeInt(filesToCompact.size());
      for (      HStoreFile hsf : filesToCompact) {
        hsf.write(out);
      }
    }
  finally {
      out.close();
    }
    Path doneFile=new Path(curCompactStore,COMPACTION_DONE);
    fs.create(doneFile).close();
    completeCompaction(curCompactStore);
    return true;
  }
}
