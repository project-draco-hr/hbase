{
  try {
    Thread.sleep(sleepBeforeFailover + (long)(rand.nextFloat() * sleepBeforeFailover));
  }
 catch (  InterruptedException e) {
    LOG.warn("Interrupted while waiting before transferring a queue.");
    Thread.currentThread().interrupt();
  }
  if (stopper.isStopped()) {
    LOG.info("Not transferring queue since we are shutting down");
    return;
  }
  SortedMap<String,SortedSet<String>> newQueues=null;
  if (conf.getBoolean(HConstants.ZOOKEEPER_USEMULTI,true)) {
    LOG.info("Atomically moving " + rsZnode + "'s hlogs to my queue");
    newQueues=zkHelper.copyQueuesFromRSUsingMulti(rsZnode);
  }
 else {
    LOG.info("Moving " + rsZnode + "'s hlogs to my queue");
    if (!zkHelper.lockOtherRS(rsZnode)) {
      return;
    }
    newQueues=zkHelper.copyQueuesFromRS(rsZnode);
    zkHelper.deleteRsQueues(rsZnode);
  }
  if (newQueues.isEmpty()) {
    return;
  }
  for (  Map.Entry<String,SortedSet<String>> entry : newQueues.entrySet()) {
    String peerId=entry.getKey();
    try {
      ReplicationSourceInterface src=getReplicationSource(conf,fs,ReplicationSourceManager.this,stopper,replicating,peerId);
      if (!zkHelper.getPeerClusters().containsKey(src.getPeerClusterId())) {
        src.terminate("Recovered queue doesn't belong to any current peer");
        break;
      }
      oldsources.add(src);
      for (      String hlog : entry.getValue()) {
        src.enqueueLog(new Path(oldLogDir,hlog));
      }
      src.startup();
    }
 catch (    IOException e) {
      LOG.error("Failed creating a source",e);
    }
  }
}
