{
  byte[] sb="sb".getBytes();
  htu.startMiniZKCluster();
  MiniHBaseCluster hbm=htu.startMiniHBaseCluster(1,1);
  hbm.waitForActiveAndReadyMaster();
  HRegionServer targetRs=hbm.getMaster();
  String host4=targetRs.getServerName().getHostname();
  LOG.info("Starting a new datanode with the name=" + host4);
  cluster.startDataNodes(conf,1,true,null,new String[]{"/r4"},new String[]{host4},null);
  cluster.waitClusterUp();
  final int repCount=3;
  conf=targetRs.getConfiguration();
  HFileSystem rfs=(HFileSystem)targetRs.getFileSystem();
  Table h=htu.createTable(TableName.valueOf("table"),sb);
  String rootDir=new Path(FSUtils.getRootDir(conf) + "/" + HConstants.HREGION_LOGDIR_NAME+ "/"+ targetRs.getServerName().toString()).toUri().getPath();
  DistributedFileSystem mdfs=(DistributedFileSystem)hbm.getMaster().getMasterFileSystem().getFileSystem();
  int nbTest=0;
  while (nbTest < 10) {
    final List<HRegion> regions=targetRs.getOnlineRegions(h.getName());
    final CountDownLatch latch=new CountDownLatch(regions.size());
    final WALActionsListener listener=new WALActionsListener.Base(){
      @Override public void postLogRoll(      final Path oldPath,      final Path newPath) throws IOException {
        latch.countDown();
      }
    }
;
    for (    HRegion region : regions) {
      region.getWAL().registerWALActionsListener(listener);
    }
    htu.getHBaseAdmin().rollWALWriter(targetRs.getServerName());
    try {
      latch.await();
    }
 catch (    InterruptedException exception) {
      LOG.warn("Interrupted while waiting for the wal of '" + targetRs + "' to roll. If later "+ "tests fail, it's probably because we should still be waiting.");
      Thread.currentThread().interrupt();
    }
    for (    HRegion region : regions) {
      region.getWAL().unregisterWALActionsListener(listener);
    }
    Thread.sleep(100);
    Put p=new Put(sb);
    p.add(sb,sb,sb);
    h.put(p);
    DirectoryListing dl=dfs.getClient().listPaths(rootDir,HdfsFileStatus.EMPTY_NAME);
    HdfsFileStatus[] hfs=dl.getPartialListing();
    Assert.assertTrue(hfs.length >= 1);
    for (    HdfsFileStatus hf : hfs) {
      try {
        LOG.info("Log file found: " + hf.getLocalName() + " in "+ rootDir);
        String logFile=rootDir + "/" + hf.getLocalName();
        FileStatus fsLog=rfs.getFileStatus(new Path(logFile));
        LOG.info("Checking log file: " + logFile);
        BlockLocation[] bls=rfs.getFileBlockLocations(fsLog,0,1);
        if (bls.length > 0) {
          BlockLocation bl=bls[0];
          LOG.info(bl.getHosts().length + " replicas for block 0 in " + logFile+ " ");
          for (int i=0; i < bl.getHosts().length - 1; i++) {
            LOG.info(bl.getHosts()[i] + "    " + logFile);
            Assert.assertNotSame(bl.getHosts()[i],host4);
          }
          String last=bl.getHosts()[bl.getHosts().length - 1];
          LOG.info(last + "    " + logFile);
          if (host4.equals(last)) {
            nbTest++;
            LOG.info(logFile + " is on the new datanode and is ok");
            if (bl.getHosts().length == 3) {
              testFromDFS(dfs,logFile,repCount,host4);
              testFromDFS(mdfs,logFile,repCount,host4);
            }
          }
        }
      }
 catch (      FileNotFoundException exception) {
        LOG.debug("Failed to find log file '" + hf.getLocalName() + "'; it probably was "+ "archived out from under us so we'll ignore and retry. If this test hangs "+ "indefinitely you should treat this failure as a symptom.",exception);
      }
catch (      RemoteException exception) {
        if (exception.unwrapRemoteException() instanceof FileNotFoundException) {
          LOG.debug("Failed to find log file '" + hf.getLocalName() + "'; it probably was "+ "archived out from under us so we'll ignore and retry. If this test hangs "+ "indefinitely you should treat this failure as a symptom.",exception);
        }
 else {
          throw exception;
        }
      }
    }
  }
}
