{
  if (this.rsServices != null && this.rsServices.isAborted()) {
    throw new IOException("Aborting flush because server is aborted...");
  }
  final long startTime=EnvironmentEdgeManager.currentTime();
  if (this.memstoreSize.get() <= 0) {
    MultiVersionConsistencyControl.WriteEntry w=null;
    this.updatesLock.writeLock().lock();
    try {
      if (this.memstoreSize.get() <= 0) {
        if (wal != null) {
          w=mvcc.beginMemstoreInsert();
          long flushSeqId=getNextSequenceId(wal);
          FlushResult flushResult=new FlushResult(FlushResult.Result.CANNOT_FLUSH_MEMSTORE_EMPTY,flushSeqId,"Nothing to flush");
          w.setWriteNumber(flushSeqId);
          mvcc.waitForPreviousTransactionsComplete(w);
          w=null;
          return flushResult;
        }
 else {
          return new FlushResult(FlushResult.Result.CANNOT_FLUSH_MEMSTORE_EMPTY,"Nothing to flush");
        }
      }
    }
  finally {
      this.updatesLock.writeLock().unlock();
      if (w != null) {
        mvcc.advanceMemstore(w);
      }
    }
  }
  if (LOG.isInfoEnabled()) {
    LOG.info("Started memstore flush for " + this + ", current region memstore size "+ StringUtils.byteDesc(this.memstoreSize.get())+ ", and "+ storesToFlush.size()+ "/"+ stores.size()+ " column families' memstores are being flushed."+ ((wal != null) ? "" : "; wal is null, using passed sequenceid=" + myseqid));
    if (this.stores.size() > storesToFlush.size()) {
      for (      Store store : storesToFlush) {
        LOG.info("Flushing Column Family: " + store.getColumnFamilyName() + " which was occupying "+ StringUtils.byteDesc(store.getMemStoreSize())+ " of memstore.");
      }
    }
  }
  MultiVersionConsistencyControl.WriteEntry w=null;
  status.setStatus("Obtaining lock to block concurrent updates");
  this.updatesLock.writeLock().lock();
  status.setStatus("Preparing to flush by snapshotting stores in " + getRegionInfo().getEncodedName());
  long totalFlushableSizeOfFlushableStores=0;
  Set<byte[]> flushedFamilyNames=new HashSet<byte[]>();
  for (  Store store : storesToFlush) {
    flushedFamilyNames.add(store.getFamily().getName());
  }
  List<StoreFlushContext> storeFlushCtxs=new ArrayList<StoreFlushContext>(stores.size());
  TreeMap<byte[],List<Path>> committedFiles=new TreeMap<byte[],List<Path>>(Bytes.BYTES_COMPARATOR);
  long flushOpSeqId=HConstants.NO_SEQNUM;
  long flushedSeqId=HConstants.NO_SEQNUM;
  byte[] encodedRegionName=getRegionInfo().getEncodedNameAsBytes();
  long trxId=0;
  try {
    try {
      w=mvcc.beginMemstoreInsert();
      if (wal != null) {
        if (!wal.startCacheFlush(encodedRegionName,flushedFamilyNames)) {
          String msg="Flush will not be started for [" + this.getRegionInfo().getEncodedName() + "] - because the WAL is closing.";
          status.setStatus(msg);
          return new FlushResult(FlushResult.Result.CANNOT_FLUSH,msg);
        }
        flushOpSeqId=getNextSequenceId(wal);
        long oldestUnflushedSeqId=wal.getEarliestMemstoreSeqNum(encodedRegionName);
        flushedSeqId=(oldestUnflushedSeqId == HConstants.NO_SEQNUM) ? flushOpSeqId : oldestUnflushedSeqId - 1;
      }
 else {
        flushedSeqId=flushOpSeqId=myseqid;
      }
      for (      Store s : storesToFlush) {
        totalFlushableSizeOfFlushableStores+=s.getFlushableSize();
        storeFlushCtxs.add(s.createFlushContext(flushOpSeqId));
        committedFiles.put(s.getFamily().getName(),null);
      }
      if (wal != null) {
        FlushDescriptor desc=ProtobufUtil.toFlushDescriptor(FlushAction.START_FLUSH,getRegionInfo(),flushOpSeqId,committedFiles);
        trxId=WALUtil.writeFlushMarker(wal,this.htableDescriptor,getRegionInfo(),desc,sequenceId,false);
      }
      for (      StoreFlushContext flush : storeFlushCtxs) {
        flush.prepare();
      }
    }
 catch (    IOException ex) {
      if (wal != null) {
        if (trxId > 0) {
          try {
            FlushDescriptor desc=ProtobufUtil.toFlushDescriptor(FlushAction.ABORT_FLUSH,getRegionInfo(),flushOpSeqId,committedFiles);
            WALUtil.writeFlushMarker(wal,this.htableDescriptor,getRegionInfo(),desc,sequenceId,false);
          }
 catch (          Throwable t) {
            LOG.warn("Received unexpected exception trying to write ABORT_FLUSH marker to WAL:" + StringUtils.stringifyException(t));
          }
        }
        wal.abortCacheFlush(this.getRegionInfo().getEncodedNameAsBytes());
        throw ex;
      }
    }
 finally {
      this.updatesLock.writeLock().unlock();
    }
    String s="Finished memstore snapshotting " + this + ", syncing WAL and waiting on mvcc, flushsize="+ totalFlushableSizeOfFlushableStores;
    status.setStatus(s);
    if (LOG.isTraceEnabled())     LOG.trace(s);
    if (wal != null) {
      try {
        wal.sync();
      }
 catch (      IOException ioe) {
        LOG.warn("Unexpected exception while wal.sync(), ignoring. Exception: " + StringUtils.stringifyException(ioe));
      }
    }
    w.setWriteNumber(flushOpSeqId);
    mvcc.waitForPreviousTransactionsComplete(w);
    w=null;
    s="Flushing stores of " + this;
    status.setStatus(s);
    if (LOG.isTraceEnabled())     LOG.trace(s);
  }
  finally {
    if (w != null) {
      mvcc.advanceMemstore(w);
    }
  }
  boolean compactionRequested=false;
  try {
    for (    StoreFlushContext flush : storeFlushCtxs) {
      flush.flushCache(status);
    }
    Iterator<Store> it=storesToFlush.iterator();
    for (    StoreFlushContext flush : storeFlushCtxs) {
      boolean needsCompaction=flush.commit(status);
      if (needsCompaction) {
        compactionRequested=true;
      }
      committedFiles.put(it.next().getFamily().getName(),flush.getCommittedFiles());
    }
    storeFlushCtxs.clear();
    this.addAndGetGlobalMemstoreSize(-totalFlushableSizeOfFlushableStores);
    if (wal != null) {
      FlushDescriptor desc=ProtobufUtil.toFlushDescriptor(FlushAction.COMMIT_FLUSH,getRegionInfo(),flushOpSeqId,committedFiles);
      WALUtil.writeFlushMarker(wal,this.htableDescriptor,getRegionInfo(),desc,sequenceId,true);
    }
  }
 catch (  Throwable t) {
    if (wal != null) {
      try {
        FlushDescriptor desc=ProtobufUtil.toFlushDescriptor(FlushAction.ABORT_FLUSH,getRegionInfo(),flushOpSeqId,committedFiles);
        WALUtil.writeFlushMarker(wal,this.htableDescriptor,getRegionInfo(),desc,sequenceId,false);
      }
 catch (      Throwable ex) {
        LOG.warn("Received unexpected exception trying to write ABORT_FLUSH marker to WAL:" + StringUtils.stringifyException(ex));
      }
      wal.abortCacheFlush(this.getRegionInfo().getEncodedNameAsBytes());
    }
    DroppedSnapshotException dse=new DroppedSnapshotException("region: " + Bytes.toStringBinary(getRegionName()));
    dse.initCause(t);
    status.abort("Flush failed: " + StringUtils.stringifyException(t));
    throw dse;
  }
  if (wal != null) {
    wal.completeCacheFlush(this.getRegionInfo().getEncodedNameAsBytes());
  }
  for (  Store store : storesToFlush) {
    this.lastStoreFlushTimeMap.put(store,startTime);
  }
  this.maxFlushedSeqId=flushedSeqId;
synchronized (this) {
    notifyAll();
  }
  long time=EnvironmentEdgeManager.currentTime() - startTime;
  long memstoresize=this.memstoreSize.get();
  String msg="Finished memstore flush of ~" + StringUtils.byteDesc(totalFlushableSizeOfFlushableStores) + "/"+ totalFlushableSizeOfFlushableStores+ ", currentsize="+ StringUtils.byteDesc(memstoresize)+ "/"+ memstoresize+ " for region "+ this+ " in "+ time+ "ms, sequenceid="+ flushOpSeqId+ ", compaction requested="+ compactionRequested+ ((wal == null) ? "; wal=null" : "");
  LOG.info(msg);
  status.setStatus(msg);
  return new FlushResult(compactionRequested ? FlushResult.Result.FLUSHED_COMPACTION_NEEDED : FlushResult.Result.FLUSHED_NO_COMPACTION_NEEDED,flushOpSeqId);
}
