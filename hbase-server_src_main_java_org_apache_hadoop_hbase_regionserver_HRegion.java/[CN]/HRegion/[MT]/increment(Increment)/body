{
  byte[] row=increment.getRow();
  checkRow(row,"increment");
  TimeRange tr=increment.getTimeRange();
  boolean flush=false;
  boolean writeToWAL=increment.getDurability() != Durability.SKIP_WAL;
  WALEdit walEdits=null;
  List<KeyValue> allKVs=new ArrayList<KeyValue>(increment.size());
  Map<Store,List<KeyValue>> tempMemstore=new HashMap<Store,List<KeyValue>>();
  long size=0;
  long txid=0;
  checkReadOnly();
  startRegionOperation();
  this.writeRequestsCount.increment();
  WriteEntry w=null;
  try {
    Integer lid=getLock(null,row,true);
    lock(this.updatesLock.readLock());
    mvcc.completeMemstoreInsert(mvcc.beginMemstoreInsert());
    w=mvcc.beginMemstoreInsert();
    try {
      long now=EnvironmentEdgeManager.currentTimeMillis();
      for (      Map.Entry<byte[],List<? extends Cell>> family : increment.getFamilyMap().entrySet()) {
        Store store=stores.get(family.getKey());
        List<KeyValue> kvs=new ArrayList<KeyValue>(family.getValue().size());
        Get get=new Get(row);
        for (        Cell cell : family.getValue()) {
          KeyValue kv=KeyValueUtil.ensureKeyValue(cell);
          get.addColumn(family.getKey(),kv.getQualifier());
        }
        get.setTimeRange(tr.getMin(),tr.getMax());
        List<KeyValue> results=get(get,false);
        int idx=0;
        for (        Cell cell : family.getValue()) {
          KeyValue kv=KeyValueUtil.ensureKeyValue(cell);
          long amount=Bytes.toLong(kv.getValue());
          byte[] qualifier=kv.getQualifier();
          if (idx < results.size() && results.get(idx).matchingQualifier(qualifier)) {
            kv=results.get(idx);
            if (kv.getValueLength() == Bytes.SIZEOF_LONG) {
              amount+=Bytes.toLong(kv.getBuffer(),kv.getValueOffset(),Bytes.SIZEOF_LONG);
            }
 else {
              throw new org.apache.hadoop.hbase.exceptions.DoNotRetryIOException("Attempted to increment field that isn't 64 bits wide");
            }
            idx++;
          }
          KeyValue newKV=new KeyValue(row,family.getKey(),qualifier,now,Bytes.toBytes(amount));
          newKV.setMemstoreTS(w.getWriteNumber());
          kvs.add(newKV);
          if (writeToWAL) {
            if (walEdits == null) {
              walEdits=new WALEdit();
            }
            walEdits.add(newKV);
          }
        }
        tempMemstore.put(store,kvs);
      }
      if (writeToWAL) {
        txid=this.log.appendNoSync(this.getRegionInfo(),this.htableDescriptor.getName(),walEdits,HConstants.DEFAULT_CLUSTER_ID,EnvironmentEdgeManager.currentTimeMillis(),this.htableDescriptor);
      }
      for (      Map.Entry<Store,List<KeyValue>> entry : tempMemstore.entrySet()) {
        Store store=entry.getKey();
        if (store.getFamily().getMaxVersions() == 1) {
          size+=store.upsert(entry.getValue(),getSmallestReadPoint());
        }
 else {
          for (          Cell cell : entry.getValue()) {
            KeyValue kv=KeyValueUtil.ensureKeyValue(cell);
            size+=store.add(kv);
          }
        }
        allKVs.addAll(entry.getValue());
      }
      size=this.addAndGetGlobalMemstoreSize(size);
      flush=isFlushSize(size);
    }
  finally {
      this.updatesLock.readLock().unlock();
      releaseRowLock(lid);
    }
    if (writeToWAL) {
      syncOrDefer(txid,increment.getDurability());
    }
  }
  finally {
    if (w != null) {
      mvcc.completeMemstoreInsert(w);
    }
    closeRegionOperation();
    if (this.metricsRegion != null) {
      this.metricsRegion.updateIncrement();
    }
  }
  if (flush) {
    requestFlush();
  }
  return new Result(allKVs);
}
