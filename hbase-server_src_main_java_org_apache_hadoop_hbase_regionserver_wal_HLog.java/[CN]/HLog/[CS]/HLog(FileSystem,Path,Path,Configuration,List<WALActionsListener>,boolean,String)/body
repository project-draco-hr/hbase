{
  super();
  this.fs=fs;
  this.dir=dir;
  this.conf=conf;
  if (listeners != null) {
    for (    WALActionsListener i : listeners) {
      registerWALActionsListener(i);
    }
  }
  this.blocksize=conf.getLong("hbase.regionserver.hlog.blocksize",getDefaultBlockSize());
  float multi=conf.getFloat("hbase.regionserver.logroll.multiplier",0.95f);
  this.logrollsize=(long)(this.blocksize * multi);
  this.optionalFlushInterval=conf.getLong("hbase.regionserver.optionallogflushinterval",1 * 1000);
  if (failIfLogDirExists && fs.exists(dir)) {
    throw new IOException("Target HLog directory already exists: " + dir);
  }
  if (!fs.mkdirs(dir)) {
    throw new IOException("Unable to mkdir " + dir);
  }
  this.oldLogDir=oldLogDir;
  if (!fs.exists(oldLogDir)) {
    if (!fs.mkdirs(this.oldLogDir)) {
      throw new IOException("Unable to mkdir " + this.oldLogDir);
    }
  }
  this.maxLogs=conf.getInt("hbase.regionserver.maxlogs",32);
  this.minTolerableReplication=conf.getInt("hbase.regionserver.hlog.tolerable.lowreplication",this.fs.getDefaultReplication());
  this.lowReplicationRollLimit=conf.getInt("hbase.regionserver.hlog.lowreplication.rolllimit",5);
  this.enabled=conf.getBoolean("hbase.regionserver.hlog.enabled",true);
  this.closeErrorsTolerated=conf.getInt("hbase.regionserver.logroll.errors.tolerated",0);
  LOG.info("HLog configuration: blocksize=" + StringUtils.byteDesc(this.blocksize) + ", rollsize="+ StringUtils.byteDesc(this.logrollsize)+ ", enabled="+ this.enabled+ ", optionallogflushinternal="+ this.optionalFlushInterval+ "ms");
  this.prefix=prefix == null || prefix.isEmpty() ? "hlog" : URLEncoder.encode(prefix,"UTF8");
  rollWriter();
  this.getNumCurrentReplicas=getGetNumCurrentReplicas(this.hdfs_out);
  logSyncerThread=new LogSyncer(this.optionalFlushInterval);
  Threads.setDaemonThreadRunning(logSyncerThread.getThread(),Thread.currentThread().getName() + ".logSyncer");
  coprocessorHost=new WALCoprocessorHost(this,conf);
}
