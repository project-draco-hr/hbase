{
  Path bulkOutputPath=new Path(util.getDataTestDirOnTestFS(tn.getNameAsString()),"hfiles");
  String INPUT_FILE="InputFile1.csv";
  String[] args=new String[]{"-D" + ImportTsv.MAPPER_CONF_KEY + "=org.apache.hadoop.hbase.mapreduce.TsvImporterTextMapper","-D" + ImportTsv.COLUMNS_CONF_KEY + "=HBASE_ROW_KEY,FAM:A,FAM:B","-D" + ImportTsv.SEPARATOR_CONF_KEY + "=,","-D" + ImportTsv.BULK_OUTPUT_CONF_KEY + "="+ bulkOutputPath.toString(),tn.getNameAsString(),INPUT_FILE};
  assertEquals("running test job configuration failed.",0,ToolRunner.run(new Configuration(util.getConfiguration()),new ImportTsv(){
    @Override public int run(    String[] args) throws Exception {
      Job job=createSubmittableJob(getConf(),args);
      assertTrue(job.getMapperClass().equals(TsvImporterTextMapper.class));
      assertTrue(job.getReducerClass().equals(TextSortReducer.class));
      assertTrue(job.getMapOutputValueClass().equals(Text.class));
      return 0;
    }
  }
,args));
  util.deleteTable(tn);
}
