{
  String jobName="TestJobForNumOfSplits";
  LOG.info("Before map/reduce startup - job " + jobName);
  Configuration c=new Configuration(TEST_UTIL.getConfiguration());
  Scan scan=new Scan();
  scan.addFamily(INPUT_FAMILY);
  c.set("hbase.mapreduce.input.autobalance","true");
  c.set("hbase.mapreduce.input.autobalance.maxskewratio",ratio);
  c.set(KEY_STARTROW,"");
  c.set(KEY_LASTROW,"");
  Job job=new Job(c,jobName);
  TableMapReduceUtil.initTableMapperJob(Bytes.toString(TABLE_NAME),scan,ScanMapper.class,ImmutableBytesWritable.class,ImmutableBytesWritable.class,job);
  TableInputFormat tif=new TableInputFormat();
  tif.setConf(job.getConfiguration());
  Assert.assertEquals(new String(TABLE_NAME),new String(table.getTableName()));
  List<InputSplit> splits=tif.getSplits(job);
  Assert.assertEquals(expectedNumOfSplits,splits.size());
}
