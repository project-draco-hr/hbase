{
  String jobName="TestJobForNumOfSplits";
  LOG.info("Before map/reduce startup - job " + jobName);
  Configuration c=new Configuration(TEST_UTIL.getConfiguration());
  Scan scan=new Scan();
  scan.addFamily(INPUT_FAMILY);
  c.set("hbase.mapreduce.input.autobalance","true");
  c.set("hbase.mapreduce.input.autobalance.maxskewratio",ratio);
  c.set(KEY_STARTROW,"");
  c.set(KEY_LASTROW,"");
  Job job=new Job(c,jobName);
  TableMapReduceUtil.initTableMapperJob(TABLE_NAME.getNameAsString(),scan,ScanMapper.class,ImmutableBytesWritable.class,ImmutableBytesWritable.class,job);
  TableInputFormat tif=new TableInputFormat();
  tif.setConf(job.getConfiguration());
  Assert.assertEquals(TABLE_NAME,table.getName());
  List<InputSplit> splits=tif.getSplits(job);
  Assert.assertEquals(expectedNumOfSplits,splits.size());
}
