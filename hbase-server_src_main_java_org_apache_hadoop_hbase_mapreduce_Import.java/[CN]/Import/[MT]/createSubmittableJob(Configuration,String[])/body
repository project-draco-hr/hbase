{
  TableName tableName=TableName.valueOf(args[0]);
  conf.set(TABLE_NAME,tableName.getNameAsString());
  Path inputDir=new Path(args[1]);
  Job job=Job.getInstance(conf,conf.get(JOB_NAME_CONF_KEY,NAME + "_" + tableName));
  job.setJarByClass(Importer.class);
  FileInputFormat.setInputPaths(job,inputDir);
  job.setInputFormatClass(SequenceFileInputFormat.class);
  String hfileOutPath=conf.get(BULK_OUTPUT_CONF_KEY);
  try {
    Class<? extends Filter> filter=conf.getClass(FILTER_CLASS_CONF_KEY,null,Filter.class);
    if (filter != null) {
      TableMapReduceUtil.addDependencyJars(conf,filter);
    }
  }
 catch (  Exception e) {
    throw new IOException(e);
  }
  if (hfileOutPath != null) {
    job.setMapperClass(KeyValueImporter.class);
    HTable table=new HTable(conf,tableName);
    job.setReducerClass(KeyValueSortReducer.class);
    Path outputDir=new Path(hfileOutPath);
    FileOutputFormat.setOutputPath(job,outputDir);
    job.setMapOutputKeyClass(ImmutableBytesWritable.class);
    job.setMapOutputValueClass(KeyValue.class);
    HFileOutputFormat2.configureIncrementalLoad(job,table,table);
    TableMapReduceUtil.addDependencyJars(job.getConfiguration(),com.google.common.base.Preconditions.class);
  }
 else {
    job.setMapperClass(Importer.class);
    TableMapReduceUtil.initTableReducerJob(tableName.getNameAsString(),null,job);
    job.setNumReduceTasks(0);
  }
  return job;
}
